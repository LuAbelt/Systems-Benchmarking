@article{Kounev,
doi	= {10.1007/978-3-030-41705-5},
title	= {Systems Benchmarking (For Scientists and Engineers)},
author	= {Kounev, Samuel and Lange, Klaus-Dieter and von Kistowski, Jóakim},
publisher = {Springer International Publishing},
journal	= {vol. 10.1007/978-3-030-41705-5},
isbn	= {9783030417048; 3030417042; 9783030417055; 3030417050},
year	= {2020},
volume	= {10.1007/978-3-030-41705-5},
url = {libgen.li/file.php?md5=93b9d1ea22ccb60d05d5e9897fcd8ce6},
}

@article{Skadron2003,
doi	= {10.1109/mc.2003.1220579},
title	= {Challenges in computer architecture evaluation},
author	= {Skadron, K. and Martonosi, M. and August, D.I. and Hill, M.D. and Lilja, D.J. and Pai, V.S.},
journal	= {Computer    vol. 36 iss. 8},
year	= {2003},
month	= {aug},
volume	= {36},
issue	= {8},
page	= {30--36},
url = {libgen.li/file.php?md5=2f01355fd88e5f3ab62a558cb376d6f2},
}

@article { mongodb,

}

@article{Wolter,
	doi	= {10.1007/978-3-642-29032-9},
	title	= {Resilience Assessment and Evaluation of Computing Systems ||},
	author	= {Wolter, Katinka and Avritzer, Alberto and Vieira, Marco and van Moorsel, Aad},
	publisher = {Springer Berlin Heidelberg},
	journal	= { vol. 10.1007/978-3-642-29032-9},
	isbn	= {9783642290312; 3642290310; 9783642290329; 3642290329},
	year	= {2012},
	volume	= {10.1007/978-3-642-29032-9},
	url =       {libgen.li/file.php?md5=2d5f326e4fe36ae7ef5c1ea116f9622d},
}

@inproceedings{kistowski2015,
author = {v. Kistowski, J\'{o}akim and Arnold, Jeremy A. and Huppler, Karl and Lange, Klaus-Dieter and Henning, John L. and Cao, Paul},
title = {How to Build a Benchmark},
year = {2015},
isbn = {9781450332484},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2668930.2688819},
doi = {10.1145/2668930.2688819},
abstract = {Standardized benchmarks have become widely accepted tools for the comparison of products
and evaluation of methodologies. These benchmarks are created by consortia like SPEC
and TPC under confidentiality agreements which provide little opportunity for outside
observers to get a look at the processes and concerns that are prevalent in benchmark
development. This paper introduces the primary concerns of benchmark development from
the perspectives of SPEC and TPC committees. We provide a benchmark definition, outline
the types of benchmarks, and explain the characteristics of a good benchmark. We focus
on the characteristics important for a standardized benchmark, as created by the SPEC
and TPC consortia. To this end, we specify the primary criteria to be employed for
benchmark design and workload selection. We use multiple standardized benchmarks as
examples to demonstrate how these criteria are ensured.},
booktitle = {Proceedings of the 6th ACM/SPEC International Conference on Performance Engineering},
pages = {333–336},
numpages = {4},
keywords = {sert, specpower_ssj2008, tpc, spec, spec cpu},
location = {Austin, Texas, USA},
series = {ICPE '15}
}

@book{huppler2009,
   title =     {Performance Evaluation and Benchmarking: First TPC Technology Conference, TPCTC 2009, Lyon, France, August 24-28, 2009, Revised Selected Papers},
   author =    {Raghunath Othayoth Nambiar, Matthew Lanken (auth.), Raghunath Nambiar, Meikel Poess (eds.)},
   publisher = {Springer-Verlag Berlin Heidelberg},
   isbn =      {3642104231; 9783642104237},
   year =      {2009},
   series =    {Lecture Notes in Computer Science 5895 : Programming and Software Engineering},
   edition =   {1},
   url =       {libgen.li/file.php?md5=f5a2262ae00462bad5df75b7f43b2dac}
}
